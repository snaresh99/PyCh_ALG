{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to CUDa Python with Numba\n",
    "\n",
    "What is CUDA?\n",
    "\n",
    "CUDA, or Compute unified device architectures, is a parallel computing platorm and programming model that allows developers to use GPUs for general purpose processing,an approach called general purpose computing on gPUs (GPGPU). CUDA API and its runtime: The CUDA API is an extension of the C programming language that adds the ability to spcify thread level parallelism in C  and also to specify GPU device specific operations (like moving data between the CPU and GPU). \n",
    "\n",
    "CUDA is a software layer that gives direct access to the GPU's virtual instruction set and parallel computaitonal elemets for the execution of compute kernels.\n",
    "\n",
    "What is compute kernel?\n",
    "* In computing, a compute kernel is a routine compiled for high throughput accelerators (such as graphic processing units (GPUs), digital signal processors (DSPs) or field programmable gate arrays (FPGAs)), separate from but used by a main program(typically running on a central processing unit). They are sometimes called compute shaders, sharing execution units with vertex shaders and pixl shaders on gPUs, but are not limited to executionon one class of device or graphics APIs.\n",
    "\n",
    "Description of Compute Kernesl:\n",
    "+++++++++++++++++++++++++++++++\n",
    "* Compute kernels roughly correspond to inner loops when implementing algorithms in traditional languages (except there is no implied sequential operation), or to code passed to internal iterators.'\n",
    "\n",
    "\n",
    "# What is Vector Processing:\n",
    "\n",
    "This programming paradigm maps well to vector processors: There is an assumption that each invocation of a kernel within a batch is independent, allowing for data parallel execution. However, atomic operations may sometimes be used for synchronization between elements (for independent work), in some scenarions.\n",
    "\n",
    "In computing, a vector processor or array processor is a central processing unit CPU that implements an instruction set where its instructions are designed to operate efficiently and effectively on large one dimensional arrays of data called vectors. this is in contrast to scalar processors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- CUDA, or compute unified device architecture, is a parallel computing platform and programmingmodel that allows developers to use GPUs for general purpose processing.\n",
    "\n",
    "CUDA enables developers to speed up compute intensive applications by offloading complex tasks from the CPU to the GPU. This is possible because GPUs have many more cores than CPUs, which are designed to perform tasks sequentially.\n",
    "- CUDA allows developers to run tasks in parallel on the GPU, which can significantly increase computing performance.\n",
    "\n",
    "CUDA is usedin manu differnent industries, including:\n",
    "a. Artific Intelligence\n",
    "b. Deep learning\n",
    "c. Scientific Computing,\n",
    "d. Machine learning reserach\n",
    "e. Medical Sciences\n",
    "f. sypercomputing.\n",
    "g. crypto mining and \n",
    "h. Scientific modeling.\n",
    "\n",
    "\n",
    "Developers can use CUDA to program in languages like c, C++ Fortran, Python, and MATLAB. The NVIDIA CUDA tool kit provides the tool need to develop GPU accelerated applications, including a compiler. GPU accelerated libraries, and the CUDA runtime.\n",
    "\n",
    "# Introduction to CUDA Python with Numba\n",
    "CUDA from Wikipedia:\n",
    "\n",
    "In computing, CUDA (originally compute unified device architecture) is a proprietary parallel computing platform and application programming interface (API) that allows software to use certain types of graphic processing units (GPUs) for accelerated general purpose processing, an approach called general purpose computing on GPUs (GPGPUs).\n",
    "\n",
    "#Parallel Computing:\n",
    " What is Parallel Computing?\n",
    "\n",
    " * Parallelization redirects here. For parallelization of manifolds, see paralellization.\n",
    "\n",
    " * Parallel computing is atype of computaiton in which many calculations or processes are carried out simultaneously. \n",
    "\n",
    "* Large problems can often be divided into smaller ones, which can then be solved at the same time. \n",
    "\n",
    "* There are several different forms of parallel computing: bit level, instruction level, data, and task parallelism. \n",
    "\n",
    "Following are the different forms of parallel computing:\n",
    "\n",
    "* bit level.\n",
    "* instruction level.\n",
    "* data.\n",
    "* task parallelism.\n",
    "\n",
    "Parallelism has long been employed in high performance computing, but has gained broasder interest due to the physical constraints preventing frequency scaling. As power consumption (and consequently heat generation) by computers have become a concern in recent years, parallel computing has become the dominant paradigm in computer architecture, mainly in the form of mult-core processors.\n",
    "\n",
    "# Multi Core Processors: MCP\n",
    "\n",
    "* A multi-core processor (MCP) is a microprocessor on a single integrated circuit (ic) with tow or more separate central processing units (CPUs) called cores to emphasize their multiplicity for ecample dual core or quad core). Each core reads and executes program instructions, specifically ordinary CPU instructions (such as add, move , data, and branch). However, the MCP can run instructions on separate cores at the same time, increasing overall speed for programs that support multithreading or other parallel computing techniques.\n",
    "\n",
    "* A multi-core processor implements multiprocessding in a single physical package. \n",
    "\n",
    "* Designers may couple cores in a multi-core device tightly or loosely. for example, cores may or may not share caches, and they may implement message passing or shared memory inter core communication methods.\n",
    "\n",
    "* Common network topologies used to interconnect cores include bus, ring, two dimentional mesh, and crossbar.\n",
    "\n",
    "* Homogeneous multi-core systems include only identical cores;\n",
    "\n",
    "* Hetrogeneous multi core systems have cores that are not identical (e.g., big.LITTLE )\n",
    "\n",
    "\n",
    "\n",
    " * Computation or computing: Is any goal oriented activity requiring, benefiting from, or creating computing machinery. It includes the study and experimentaiton of algorithmic process, and the development of both hardware and software. Computing has scientific, engineering, and mathematical technological, and social aspects. Major computing disciplines include computer engineering, computer science cybersecurity, data science, information systems, informaiton technology, and software engineering.\n",
    "\n",
    " * It includes the study and experimentation of algorithmic process, and the development of both hardware and software.\n",
    "\n",
    " * computing has scientific, engineering, and mathematical technological, social aspects. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
